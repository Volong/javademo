>   翻译自：https://lucidworks.com/2018/06/20/solr-and-optimizing-your-index-take-ii/

优化 (optimize) 与删除不再跟之前一样糟糕。但是也不应该随便使用，因为它所需要的成本依然很高。也就是说，这些操作不再那么容易受[这篇文章](https://lucidworks.com/2017/10/13/segment-merging-deleted-documents-optimize-may-bad/)中列出的问题的影响。如果你对 Solr/Lucene 中的段合并操作不那么熟悉，那篇文章可以给你一些背景知识。

## 摘要

-   从 Solr 7.5 开始，删除与优化 / 强制合并的的默认实现 `TieredMergePolicy (TMP) ` 将有完全不同的表现
-   `TieredMergePolicy` 将有一些额外的选项用来控制在一个索引中删除文档的百分比。 见 [LUCENE-8263](https://issues.apache.org/jira/browse/LUCENE-8263)
-   `TMP` 对于强制合并与删除有一个默认的参数 *maxMergedSegmentMB* 
-   如果想要执行以前强制合并 (优化) 的操作，可以通过命令指定 `maxSegments`
-   删除不会超过 `maxMergedSegmentMB` 指定的值
-   如果创建了非常大的段，随着删除的文档在段中的堆积。这个段将会"单独合并"，用于清理掉那些已经被删除的文档。注意：只有当索引中有接近 50% 的文档被删除时，这种情况才会发生。有可能后续会对这种情况进行调节

## 介绍

不久之前，我写了一篇关于使用 Solr 的 [优化以及删除的提交选项](https://lucidworks.com/2017/10/13/segment-merging-deleted-documents-optimize-may-bad/) 的文章。随着 Solr 7.5 的到来，文章中提到的最坏情况将不会出现。如果你想要知道更多的细节，可以参考 [LUCENE-7976](https://issues.apache.org/jira/browse/LUCENE-7976) 以及相关的 JIRA。

在 Solr 7.5 中，优化 (又名强制删除) 以及删除使用 `TieredMergePolicy` 作为默认以及推荐的合并策略，并且遵循 *maxMergedSegmentMB* 参数的配置。

这样一个简短的介绍，涉及到一些重要的方面，因此将这篇文章发了出来。

## 快速回顾 Solr 7.5 之前的合并以及删除

首先快速回顾一下，通过命令去执行优化或者删除操作，默认的行为是任何合并的段将会被合并成一个段，*而不管最终的结果段会变成多大*。

-   对于优化操作，整个索引将会被合并到 `maxSegments` 参数 (默认为 1) 指定的个数的段中。
-   对于删除操作，所有删除的文档超过 10% 的段会被合并到一个段中。

对于"自然"合并，当索引被更新时，每次硬提交都会进行如下的初始化操作：

-   所有"活着"的文档小于 `maxMergedSegmentMB` 50% 的段都会被检查，被选中的段会进行合并。
-   "被选中的段"意味着使用启发式算法来尝试选择最少工作量的合并，并且依然会遵循 `maxMergedSegmentMB`。

关键的不同在于优化/强制合并与删除*并不遵循 maxMergedSegmentMB*。

### 之前为什么要实现 maxMergedSegmentMB?

关于这点，有过很长的讨论，但是我并不想谈论这个。因为保持索引更新需要去解决一些相互竞争，而 `maxMergedSegmentMB` 是解决这些问题的一部分。需要权衡的点包括：

-   控制 I/O，因为索引以及搜索对 I/O 瓶颈敏感
-   控制段数，防止耗尽文件句柄数等
-   控制内存消耗，仅仅为了索引而要求分配 5G 的内存在堆上是不可接受的
-   最开始的时候，通过合并到一个段，可以显著的提高速度，但是最新版本的 Solr 没有同等程度的提升

## 新方法

在 Solr 7.5 中，优化 (又名强制合并) 以及删除使用跟"自然合并"一样的算法。"自然合并"，"强制合并"，"删除" 之间的差别在于选择什么样的段去进行合并。有下面三种情况：

-   **自然合并**：所有的段都会被考虑合并。这是将文档索引到 Solr/Lucene 的常规操作。通过对各种可能性进行评分，通过大概的计算以及对 I/O 的估计来选择消耗最少的可能性。因为删除大的段不会被认为消耗较少，所以很少被合并。
-   **删除**：删除文档数大于 10% 的段，不管段多大，都会被考虑进行合并。
-   **优化**：又分两种情况，是否指定了 `maxSegments`：
    -   是：所有的段都会被考虑进去
    -   否：所有"活着"的文档小于 `maxMergedSegmentMB` 的段以及所有包含删除文档的段会被考虑进去。所以，没有文档被删除且大于 `maxMergedSegmentMB` 的段不会被考虑。

（等一下！你哭着对我说😂）你之前告诉我们删除以及优化/强制合并遵循 `maxMergedSegmentMB`，但是现在你又说可以通过指定 `maxSegments = 1` 并且段数可以大于 `maxMergedSegmentMB`。这到底是怎么肥事？我很开心你可以这样问 （作者在自问自答😂，后面还有一大句是作者用来解释为什么喜欢自问自答的，懒得翻了）。

在 Solr 7.5 中，TMP 引入了"单独合并"。当一个段可以进行合并时，如果它太大了，它将会被重新写入到一个新段中，并移除掉被删除的文档。

这里有一些有意思的结果。假设你已经优化到了 1 个段，开始索引更多的文档，将会触发删除。这篇文章顶部链接里的文章详细说明了它的缺点。也就是说单个大的段不会被合并直到它的主要组成部分为已删除的文档。但是现在不再是这样的了。当满足其他的条件时，"单独合并"将会在大段上执行，本质上会重新写入到 1 个新的段，并且移除掉被删除的文档。它的大小将会被逐渐收缩到 `maxMergedSegmentMB` 一下，在这点上跟其它的段类似。

警告：这会增加 I/O 的成本。假设有一个段的大小为 200GB，包含了 20% 已经被删除的文档，并且被选中进行单独合并。在由合并算法决定的某个点，需要重写 160GB，并提供了一种从本篇文章顶部链接中的文章列出的状况中去恢复的方法，该方法不需要重新索引，但是最好一开始就不要陷入到这种状况当中。

